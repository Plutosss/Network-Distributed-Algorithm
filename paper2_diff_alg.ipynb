{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "paper2_diff_alg",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-B_9X_U83DYgvJCMxo2Ni_a-VCqh3puF",
      "authorship_tag": "ABX9TyNTxrpDDdkYQ1cQBWEKq5ep",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Plutosss/Network-Distributed-Algorithm/blob/master/paper2_diff_alg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84SCevPer-FC"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbQ01CBBSgxB"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i55hAZtQS1lv"
      },
      "source": [
        "!rm -rf /content/sample_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlKgHSLvS-sc"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Network-Distributed-Algorithm-master')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBxaWvymTGlo"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "#读取文件\n",
        "dataFile = 'pd_speech_features.csv'\n",
        "data =  pd.read_csv(dataFile)\n",
        "data = shuffle(data)\n",
        "features = data.loc[:, 'gender':'tqwt_kurtosisValue_dec_36']\n",
        "print('特征里是否有Nan值:',features.isnull().values.any())\n",
        "\n",
        "# 数据处理\n",
        "X_total = (features - features.mean()) / (features.std())\n",
        "X_total['const'] = np.ones(features.shape[0]) #常数列\n",
        "X_total = X_total.to_numpy()\n",
        "Y_total = data.iloc[:, -1].values\n",
        "#print(X_total[:5],Y_total[:5])\n",
        "\n",
        "\n",
        "m, dim = X_total.shape\n",
        "print(m,dim)\n",
        "\n",
        "n_agent = 12\n",
        "kappa =10\n",
        "mu = 5e-5  # we set mu=5e-10 when kappa = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE1r2s9IWNqd"
      },
      "source": [
        "$tmp = X\\ total@w$\n",
        "\n",
        "$f(w) = \\sum \\big((Y\\ total - 1) * tmp - np.log(1 + np.exp(-tmp))\n",
        "                    \\big) /m\\ total + sum(w**2) * LAMBDA / 2$\n",
        "\n",
        "$g(w) = X\\ total.T @ (logit(X\\ total, w) - Y\\ total) / m\\ total + w * LAMBDA $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6LDMbYIUWCv"
      },
      "source": [
        "from problems import *\n",
        "p = SparseLogisticRegression(n_agent, m, dim, X_total=X_total, Y_total=Y_total, prob=0.3) #修改了f_min 和x_min节省时间\n",
        "#print('alpha = ' + str(alpha))\n",
        "#print(W.sum(axis=0))\n",
        "#print(W.sum(axis=1))\n",
        "print('Lips:',p.L)\n",
        "print('mu:',p.sigma)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8ZwPKceFFJ1"
      },
      "source": [
        "p.x_min.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNijFNXMoJGq"
      },
      "source": [
        "import random\n",
        "from optimizers.utils import generate_mixing_matrix, generate_R_matrix, generate_C_matrix\n",
        "W, alpha = generate_mixing_matrix(p)\n",
        "R, alpha = generate_R_matrix(p)\n",
        "C, alpha = generate_C_matrix(p)\n",
        "\n",
        "\n",
        "# 步长使用1e-4 误差能精确到 \n",
        "eta_1 = 1 / p.L\n",
        "eta_2 = 2 / (p.L + p.sigma)\n",
        "\n",
        "eig_min = np.min(np.abs(np.linalg.eigvals(W)))\n",
        "print('最小特征值:',eig_min)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmNnwYE9t3sl"
      },
      "source": [
        "!rm -rf /content/drive/MyDrive/Network-Distributed-Algorithm-master/data/*\n",
        "!rm -rf /content/drive/MyDrive/Network-Distributed-Algorithm-master/figs/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6tvJtYqs-JR"
      },
      "source": [
        "random.seed(1)\n",
        "x_0 = np.random.rand(dim, n_agent)+0.5*np.repeat(np.expand_dims(p.x_min,axis=1),n_agent,axis=1)\n",
        "\n",
        "from optimizers import *\n",
        "from utils import run_exp\n",
        "\n",
        "\n",
        "n_iters = 1000\n",
        "n_dgd_iters = n_iters * 1\n",
        "\n",
        "distributed = [\n",
        "    DSGD(p, n_iters=n_dgd_iters, eta=eta_1, x_0=x_0, W=W, diminish=True, verbose=True),\n",
        "    #EXTRA(p, n_iters=n_dgd_iters, eta=0.01, x_0=x_0, W=W), # or p.L/624 the step size bound by eig_min/p.L, proved pushi \n",
        "    \n",
        "\n",
        "    ]\n",
        "RC = [\n",
        "    PushDIGing(p, n_iters=n_dgd_iters, eta=0.025, x_0=x_0, R=R, C=C),\n",
        "    DGD_tracking(p, n_iters=n_dgd_iters, eta=0.03, x_0=x_0, W=W),\n",
        "    PushPull(p, n_iters=n_dgd_iters, eta=0.03, x_0=x_0, R=R, C=C),\n",
        "    PEXTRA(p, n_iters=n_dgd_iters, eta=0.04, x_0=x_0, W=W),\n",
        "    PGPushPull(p, n_iters=n_dgd_iters, eta=0.04, x_0=x_0, R=R, C=C)#突出PGPushPull\n",
        "    ]\n",
        "exps = distributed + RC\n",
        "res = run_exp(exps, kappa=kappa, max_iter=n_iters, name='sparse_logistic_regression', n_process=1, save=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAZRedzMjqss"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('/content/drive/MyDrive/Network-Distributed-Algorithm-master/figs/sparse_logistic_regression_kappa_10_fval_iter.eps')\n",
        "files.download('/content/drive/MyDrive/Network-Distributed-Algorithm-master/figs/sparse_logistic_regression_kappa_10_var_iter.eps')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}